{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 定义简单的两层神经网络\n",
    "class RZDecoderNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RZDecoderNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 从文件中加载数据\n",
    "def load_data_from_file(file_path, bit_length):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = [float(x) for x in line.strip().split()]\n",
    "            inputs.append(values[:bit_length])  # 前 bit_length 个值为输入信号\n",
    "            outputs.append(values[bit_length])  # 最后一个值为输出标签\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.float32).unsqueeze(1)  # 添加维度以匹配网络输出\n",
    "    return inputs, outputs\n",
    "\n",
    "def load_data_from_file_exp(file_path, bit_length):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = [float(x) for x in line.strip().split()]\n",
    "            inputs.append(values[:bit_length])  # 前 bit_length 个值为输入信号\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.float32).unsqueeze(1)  # 添加维度以匹配网络输出\n",
    "    return inputs, outputs\n",
    "\n",
    "# 训练 RZ 解码网络\n",
    "def train_rz_decoder(model, train_loader, num_epochs=20, learning_rate=0.01):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 使用加载的模型进行预测\n",
    "def predict_with_model(model, inputs):\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs >= 0.5).float()  # 阈值设为 0.5，输出 0 或 1\n",
    "    return predictions\n",
    "\n",
    "# 参数\n",
    "bit_length = 2  # 每个比特的长度为 1\n",
    "\n",
    "# 文件路径\n",
    "train_file_path = r'E:\\gitprogram\\data\\testdata\\train.txt'\n",
    "test_file_path = r'E:\\gitprogram\\data\\testdata\\test.txt'\n",
    "exp_file_path = r'E:\\gitprogram\\data\\testdata\\exp.txt'\n",
    "\n",
    "# 从文件加载训练和测试数据\n",
    "train_inputs, train_labels = load_data_from_file(train_file_path, bit_length)\n",
    "test_inputs, test_labels = load_data_from_file(test_file_path, bit_length)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 初始化网络\n",
    "input_size = bit_length\n",
    "model = RZDecoderNet(input_size)\n",
    "\n",
    "# 训练网络\n",
    "train_rz_decoder(model, train_loader, num_epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# 保存训练后的模型\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载已训练的模型\n",
    "model.load_state_dict(torch.load('trained_model.pth'))\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 读取实验数据\n",
    "exp_inputs, _ = load_data_from_file_exp(exp_file_path, bit_length)\n",
    "\n",
    "# 进行预测\n",
    "predicted_outputs = predict_with_model(model, exp_inputs)\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"Predicted outputs:\", predicted_outputs.squeeze().int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Training Loss: 0.2606, Validation Loss: 0.1944\n",
      "Best model saved with validation loss: 0.1944\n",
      "Epoch [2/2000], Training Loss: -0.2335, Validation Loss: -0.3284\n",
      "Best model saved with validation loss: -0.3284\n",
      "Epoch [3/2000], Training Loss: -1.5287, Validation Loss: -0.8776\n",
      "Best model saved with validation loss: -0.8776\n",
      "Epoch [4/2000], Training Loss: -2.4849, Validation Loss: -1.5144\n",
      "Best model saved with validation loss: -1.5144\n",
      "Epoch [5/2000], Training Loss: -0.6860, Validation Loss: -2.2385\n",
      "Best model saved with validation loss: -2.2385\n",
      "Epoch [6/2000], Training Loss: -1.1648, Validation Loss: -3.1059\n",
      "Best model saved with validation loss: -3.1059\n",
      "Epoch [7/2000], Training Loss: -1.8567, Validation Loss: -4.1922\n",
      "Best model saved with validation loss: -4.1922\n",
      "Epoch [8/2000], Training Loss: -2.1655, Validation Loss: -5.4462\n",
      "Best model saved with validation loss: -5.4462\n",
      "Epoch [9/2000], Training Loss: 0.0288, Validation Loss: -6.9257\n",
      "Best model saved with validation loss: -6.9257\n",
      "Epoch [10/2000], Training Loss: -0.1361, Validation Loss: -41.5758\n",
      "Best model saved with validation loss: -41.5758\n",
      "Epoch [11/2000], Training Loss: -37.9184, Validation Loss: -50.2942\n",
      "Best model saved with validation loss: -50.2942\n",
      "Epoch [12/2000], Training Loss: -79.8441, Validation Loss: -50.8610\n",
      "Best model saved with validation loss: -50.8610\n",
      "Epoch [13/2000], Training Loss: -63.0734, Validation Loss: -51.1800\n",
      "Best model saved with validation loss: -51.1800\n",
      "Epoch [14/2000], Training Loss: -79.9516, Validation Loss: -51.3996\n",
      "Best model saved with validation loss: -51.3996\n",
      "Epoch [15/2000], Training Loss: -39.8002, Validation Loss: -59.8673\n",
      "Best model saved with validation loss: -59.8673\n",
      "Epoch [16/2000], Training Loss: -19.8654, Validation Loss: -59.9276\n",
      "Best model saved with validation loss: -59.9276\n",
      "Epoch [17/2000], Training Loss: -59.9248, Validation Loss: -59.9545\n",
      "Best model saved with validation loss: -59.9545\n",
      "Epoch [18/2000], Training Loss: -19.9513, Validation Loss: -59.9662\n",
      "Best model saved with validation loss: -59.9662\n",
      "Epoch [19/2000], Training Loss: -43.1602, Validation Loss: -59.9735\n",
      "Best model saved with validation loss: -59.9735\n",
      "Epoch [20/2000], Training Loss: -39.9607, Validation Loss: -59.9772\n",
      "Best model saved with validation loss: -59.9772\n",
      "Epoch [21/2000], Training Loss: -83.1885, Validation Loss: -59.9810\n",
      "Best model saved with validation loss: -59.9810\n",
      "Epoch [22/2000], Training Loss: -59.9938, Validation Loss: -59.9824\n",
      "Best model saved with validation loss: -59.9824\n",
      "Epoch [23/2000], Training Loss: -79.9985, Validation Loss: -59.9851\n",
      "Best model saved with validation loss: -59.9851\n",
      "Epoch [24/2000], Training Loss: -59.9920, Validation Loss: -59.9876\n",
      "Best model saved with validation loss: -59.9876\n",
      "Epoch [25/2000], Training Loss: -100.0000, Validation Loss: -59.9893\n",
      "Best model saved with validation loss: -59.9893\n",
      "Epoch [26/2000], Training Loss: -59.9927, Validation Loss: -59.9892\n",
      "Epoch [27/2000], Training Loss: -59.9939, Validation Loss: -59.9901\n",
      "Best model saved with validation loss: -59.9901\n",
      "Epoch [28/2000], Training Loss: -59.9963, Validation Loss: -59.9912\n",
      "Best model saved with validation loss: -59.9912\n",
      "Epoch [29/2000], Training Loss: -39.9943, Validation Loss: -59.9918\n",
      "Best model saved with validation loss: -59.9918\n",
      "Epoch [30/2000], Training Loss: -59.9988, Validation Loss: -59.9920\n",
      "Best model saved with validation loss: -59.9920\n",
      "Epoch [31/2000], Training Loss: -79.9984, Validation Loss: -59.9924\n",
      "Best model saved with validation loss: -59.9924\n",
      "Epoch [32/2000], Training Loss: -19.9882, Validation Loss: -59.9931\n",
      "Best model saved with validation loss: -59.9931\n",
      "Epoch [33/2000], Training Loss: -79.9994, Validation Loss: -59.9938\n",
      "Best model saved with validation loss: -59.9938\n",
      "Epoch [34/2000], Training Loss: -39.9957, Validation Loss: -59.9940\n",
      "Best model saved with validation loss: -59.9940\n",
      "Epoch [35/2000], Training Loss: -59.9917, Validation Loss: -59.9942\n",
      "Best model saved with validation loss: -59.9942\n",
      "Epoch [36/2000], Training Loss: -19.9918, Validation Loss: -59.9947\n",
      "Best model saved with validation loss: -59.9947\n",
      "Epoch [37/2000], Training Loss: -39.9938, Validation Loss: -59.9952\n",
      "Best model saved with validation loss: -59.9952\n",
      "Epoch [38/2000], Training Loss: -39.9940, Validation Loss: -59.9954\n",
      "Best model saved with validation loss: -59.9954\n",
      "Epoch [39/2000], Training Loss: -19.9962, Validation Loss: -59.9954\n",
      "Best model saved with validation loss: -59.9954\n",
      "Epoch [40/2000], Training Loss: -59.9980, Validation Loss: -59.9957\n",
      "Best model saved with validation loss: -59.9957\n",
      "Epoch [41/2000], Training Loss: -39.9955, Validation Loss: -59.9960\n",
      "Best model saved with validation loss: -59.9960\n",
      "Epoch [42/2000], Training Loss: -39.9946, Validation Loss: -59.9963\n",
      "Best model saved with validation loss: -59.9963\n",
      "Epoch [43/2000], Training Loss: -59.9974, Validation Loss: -59.9966\n",
      "Best model saved with validation loss: -59.9966\n",
      "Epoch [44/2000], Training Loss: -39.9980, Validation Loss: -59.9965\n",
      "Epoch [45/2000], Training Loss: -39.9933, Validation Loss: -59.9965\n",
      "Epoch [46/2000], Training Loss: -19.9937, Validation Loss: -59.9966\n",
      "Best model saved with validation loss: -59.9966\n",
      "Epoch [47/2000], Training Loss: -59.9991, Validation Loss: -59.9969\n",
      "Best model saved with validation loss: -59.9969\n",
      "Epoch [48/2000], Training Loss: -39.9937, Validation Loss: -59.9971\n",
      "Best model saved with validation loss: -59.9971\n",
      "Epoch [49/2000], Training Loss: -39.9981, Validation Loss: -59.9973\n",
      "Best model saved with validation loss: -59.9973\n",
      "Epoch [50/2000], Training Loss: -39.9985, Validation Loss: -59.9972\n",
      "Epoch [51/2000], Training Loss: -39.9947, Validation Loss: -59.9971\n",
      "Epoch [52/2000], Training Loss: -79.9992, Validation Loss: -59.9972\n",
      "Epoch [53/2000], Training Loss: -59.9953, Validation Loss: -59.9974\n",
      "Best model saved with validation loss: -59.9974\n",
      "Epoch [54/2000], Training Loss: -39.9964, Validation Loss: -59.9975\n",
      "Best model saved with validation loss: -59.9975\n",
      "Epoch [55/2000], Training Loss: -39.9958, Validation Loss: -59.9977\n",
      "Best model saved with validation loss: -59.9977\n",
      "Epoch [56/2000], Training Loss: -59.9987, Validation Loss: -59.9978\n",
      "Best model saved with validation loss: -59.9978\n",
      "Epoch [57/2000], Training Loss: -59.9961, Validation Loss: -59.9979\n",
      "Best model saved with validation loss: -59.9979\n",
      "Epoch [58/2000], Training Loss: -59.9973, Validation Loss: -59.9981\n",
      "Best model saved with validation loss: -59.9981\n",
      "Epoch [59/2000], Training Loss: -59.9969, Validation Loss: -59.9979\n",
      "Epoch [60/2000], Training Loss: -39.9973, Validation Loss: -59.9978\n",
      "Epoch [61/2000], Training Loss: -79.9989, Validation Loss: -59.9979\n",
      "Epoch [62/2000], Training Loss: -39.9981, Validation Loss: -59.9980\n",
      "Epoch [63/2000], Training Loss: -79.9995, Validation Loss: -59.9981\n",
      "Best model saved with validation loss: -59.9981\n",
      "Epoch [64/2000], Training Loss: -79.9998, Validation Loss: -59.9982\n",
      "Best model saved with validation loss: -59.9982\n",
      "Epoch [65/2000], Training Loss: -79.9998, Validation Loss: -59.9983\n",
      "Best model saved with validation loss: -59.9983\n",
      "Epoch [66/2000], Training Loss: -39.9987, Validation Loss: -59.9984\n",
      "Best model saved with validation loss: -59.9984\n",
      "Epoch [67/2000], Training Loss: -79.9986, Validation Loss: -59.9984\n",
      "Best model saved with validation loss: -59.9984\n",
      "Epoch [68/2000], Training Loss: -39.9981, Validation Loss: -59.9985\n",
      "Best model saved with validation loss: -59.9985\n",
      "Epoch [69/2000], Training Loss: -59.9978, Validation Loss: -59.9986\n",
      "Best model saved with validation loss: -59.9986\n",
      "Epoch [70/2000], Training Loss: -79.9999, Validation Loss: -59.9986\n",
      "Best model saved with validation loss: -59.9986\n",
      "Epoch [71/2000], Training Loss: -79.9996, Validation Loss: -59.9987\n",
      "Best model saved with validation loss: -59.9987\n",
      "Epoch [72/2000], Training Loss: -59.9979, Validation Loss: -59.9986\n",
      "Epoch [73/2000], Training Loss: -59.9987, Validation Loss: -59.9985\n",
      "Epoch [74/2000], Training Loss: -39.9992, Validation Loss: -59.9985\n",
      "Epoch [75/2000], Training Loss: -59.9990, Validation Loss: -59.9985\n",
      "Epoch [76/2000], Training Loss: -39.9984, Validation Loss: -59.9986\n",
      "Early stopping due to no improvement in validation loss.\n",
      "Predicted outputs: tensor([1, 0, 1, 1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "# 定义简单的两层神经网络\n",
    "class RZDecoderNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RZDecoderNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 从文件中加载数据\n",
    "def load_data_from_file(file_path, bit_length):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = [float(x) for x in line.strip().split()]\n",
    "            inputs.append(values[:bit_length])  # 前 bit_length 个值为输入信号\n",
    "            outputs.append(values[bit_length])  # 最后一个值为输出标签\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.float32).unsqueeze(1)  # 添加维度以匹配网络输出\n",
    "    return inputs, outputs\n",
    "\n",
    "def load_data_from_file_exp(file_path, bit_length):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = [float(x) for x in line.strip().split()]\n",
    "            inputs.append(values[:bit_length])  # 前 bit_length 个值为输入信号\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.float32).unsqueeze(1)  # 添加维度以匹配网络输出\n",
    "    return inputs, outputs\n",
    "\n",
    "# 训练 RZ 解码网络\n",
    "def train_rz_decoder(model, train_loader, val_loader, num_epochs=20, learning_rate=0.01, model_save_path='best_model.pth'):\n",
    "    criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')  # 最优验证损失初始化为正无穷\n",
    "    patience = 5  # 如果验证损失在连续 5 个 epoch 中没有下降，则停止训练\n",
    "    counter = 0  # 用于计算验证损失没有下降的次数\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 进入训练模式\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 在每个 epoch 结束后，评估模型在验证集上的表现\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # 保存最优模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0  # 重置计数器\n",
    "            torch.save(model.state_dict(), model_save_path)  # 保存当前模型\n",
    "            print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "# 验证模型\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# 使用加载的模型进行预测\n",
    "def predict_with_model(model, inputs):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs >= 0.5).float()  # 阈值设为 0.5，输出 0 或 1\n",
    "    return predictions\n",
    "\n",
    "# 参数\n",
    "bit_length = 2  # 每个比特的长度为 1\n",
    "\n",
    "# 文件路径\n",
    "train_file_path = r'E:\\gitprogram\\data\\testdata\\train.txt'\n",
    "test_file_path = r'E:\\gitprogram\\data\\testdata\\test.txt'\n",
    "exp_file_path = r'E:\\gitprogram\\data\\testdata\\exp.txt'\n",
    "\n",
    "# 从文件加载训练和测试数据\n",
    "train_inputs, train_labels = load_data_from_file(train_file_path, bit_length)\n",
    "test_inputs, test_labels = load_data_from_file(test_file_path, bit_length)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 创建验证数据加载器\n",
    "val_dataset = TensorDataset(test_inputs, test_labels)  # 将测试数据作为验证集\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# 初始化网络\n",
    "input_size = bit_length\n",
    "model = RZDecoderNet(input_size)\n",
    "\n",
    "# 训练网络并保存最优模型\n",
    "train_rz_decoder(model, train_loader, val_loader, num_epochs=2000, learning_rate=0.01, model_save_path='best_model.pth')\n",
    "\n",
    "# 加载最优模型\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 读取实验数据\n",
    "exp_inputs, _ = load_data_from_file_exp(exp_file_path, bit_length)\n",
    "\n",
    "# 进行预测\n",
    "predicted_outputs = predict_with_model(model, exp_inputs)\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"Predicted outputs:\", predicted_outputs.squeeze().int())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
